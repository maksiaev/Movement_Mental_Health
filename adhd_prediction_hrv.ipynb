{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ADHD Classification Based on HRV\n",
    "# Purpose: Determine whether heart rate variability can predict diagnosis of ADHD\n",
    "# Author: Alexander Maksiaev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>SEX</th>\n",
       "      <th>AGE</th>\n",
       "      <th>ACC</th>\n",
       "      <th>ACC_TIME</th>\n",
       "      <th>ACC_DAYS</th>\n",
       "      <th>HRV</th>\n",
       "      <th>HRV_TIME</th>\n",
       "      <th>HRV_HOURS</th>\n",
       "      <th>CPT_II</th>\n",
       "      <th>...</th>\n",
       "      <th>HADS_D</th>\n",
       "      <th>MED</th>\n",
       "      <th>MED_Antidepr</th>\n",
       "      <th>MED_Moodstab</th>\n",
       "      <th>MED_Antipsych</th>\n",
       "      <th>MED_Anxiety_Benzo</th>\n",
       "      <th>MED_Sleep</th>\n",
       "      <th>MED_Analgesics_Opioids</th>\n",
       "      <th>MED_Stimulants</th>\n",
       "      <th>filter_$</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>01</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>16:00:00</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>11:00:00</td>\n",
       "      <td>21.0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>02</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>10:54:00</td>\n",
       "      <td>6.8</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>03</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>15:28:00</td>\n",
       "      <td>7.2</td>\n",
       "      <td>1</td>\n",
       "      <td>15:25:00</td>\n",
       "      <td>21.0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>04</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>16:55:00</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>05</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>14:24:00</td>\n",
       "      <td>5.9</td>\n",
       "      <td>1</td>\n",
       "      <td>16:00:00</td>\n",
       "      <td>12.0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>129</th>\n",
       "      <td>236</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>9:30:00</td>\n",
       "      <td>13,3</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>130</th>\n",
       "      <td>237</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>15:00:00</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>131</th>\n",
       "      <td>238</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>9:00:00</td>\n",
       "      <td>14,6</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>132</th>\n",
       "      <td>239</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>9:00:00</td>\n",
       "      <td>14,3</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>133</th>\n",
       "      <td>240</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>9:00:00</td>\n",
       "      <td>14,6</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>134 rows Ã— 33 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      ID  SEX  AGE  ACC  ACC_TIME ACC_DAYS  HRV  HRV_TIME  HRV_HOURS  CPT_II  \\\n",
       "0     01    0    3    1  16:00:00        6    1  11:00:00       21.0       0   \n",
       "1     02    0    4    1  10:54:00      6.8    0       NaN        NaN       1   \n",
       "2     03    1    2    1  15:28:00      7.2    1  15:25:00       21.0       1   \n",
       "3     04    1    3    0       NaN      NaN    1  16:55:00       22.0       1   \n",
       "4     05    1    1    1  14:24:00      5.9    1  16:00:00       12.0       1   \n",
       "..   ...  ...  ...  ...       ...      ...  ...       ...        ...     ...   \n",
       "129  236    1    2    1   9:30:00     13,3    0       NaN        NaN       0   \n",
       "130  237    0    1    1  15:00:00       14    0       NaN        NaN       0   \n",
       "131  238    0    4    1   9:00:00     14,6    0       NaN        NaN       0   \n",
       "132  239    0    4    1   9:00:00     14,3    0       NaN        NaN       0   \n",
       "133  240    1    1    1   9:00:00     14,6    0       NaN        NaN       0   \n",
       "\n",
       "     ...  HADS_D  MED  MED_Antidepr  MED_Moodstab  MED_Antipsych  \\\n",
       "0    ...     2.0  1.0           1.0           NaN            NaN   \n",
       "1    ...     7.0  0.0           NaN           NaN            NaN   \n",
       "2    ...     0.0  0.0           NaN           NaN            NaN   \n",
       "3    ...     6.0  1.0           1.0           NaN            NaN   \n",
       "4    ...     5.0  0.0           NaN           NaN            NaN   \n",
       "..   ...     ...  ...           ...           ...            ...   \n",
       "129  ...     NaN  NaN           NaN           NaN            NaN   \n",
       "130  ...     NaN  NaN           NaN           NaN            NaN   \n",
       "131  ...     NaN  NaN           NaN           NaN            NaN   \n",
       "132  ...     NaN  NaN           NaN           NaN            NaN   \n",
       "133  ...     NaN  NaN           NaN           NaN            NaN   \n",
       "\n",
       "     MED_Anxiety_Benzo  MED_Sleep  MED_Analgesics_Opioids  MED_Stimulants  \\\n",
       "0                  NaN        NaN                     NaN             NaN   \n",
       "1                  NaN        NaN                     NaN             NaN   \n",
       "2                  NaN        NaN                     NaN             NaN   \n",
       "3                  1.0        NaN                     1.0             NaN   \n",
       "4                  NaN        NaN                     NaN             NaN   \n",
       "..                 ...        ...                     ...             ...   \n",
       "129                NaN        NaN                     NaN             NaN   \n",
       "130                NaN        NaN                     NaN             NaN   \n",
       "131                NaN        NaN                     NaN             NaN   \n",
       "132                NaN        NaN                     NaN             NaN   \n",
       "133                NaN        NaN                     NaN             NaN   \n",
       "\n",
       "     filter_$  \n",
       "0         1.0  \n",
       "1         1.0  \n",
       "2         1.0  \n",
       "3         0.0  \n",
       "4         1.0  \n",
       "..        ...  \n",
       "129       NaN  \n",
       "130       NaN  \n",
       "131       NaN  \n",
       "132       NaN  \n",
       "133       NaN  \n",
       "\n",
       "[134 rows x 33 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Housekeeping\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sklearn \n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from xgboost import XGBClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "import glob\n",
    "import os\n",
    "import csv \n",
    "from datetime import datetime\n",
    "from sktime.classification.feature_based import RandomIntervalClassifier\n",
    "from sktime.transformations.panel.padder import PaddingTransformer\n",
    "import sktime.datasets\n",
    "\n",
    "\n",
    "# Directories\n",
    "\n",
    "adhd_dir_raw = \"C:/Users\\maksi\\Documents\\Statistics\\Projects\\Movement_Mental_Health\\hyperaktiv\\hyperaktiv_with_controls\\hyperaktiv_with_controls\"\n",
    "adhd_dir = adhd_dir_raw.replace(\"\\\\\", \"/\") # Not gonna change all that manually \n",
    "activity_dir = os.path.join(adhd_dir, \"activity_data\")\n",
    "hrv_dir = os.path.join(adhd_dir, \"hrv_data\")\n",
    "output_dir = os.path.join(adhd_dir, \"pt_features\") \n",
    "# controls_dir = os.path.join(adhd_dir, \"hyperaktiv_with_controls/hyperaktiv_with_controls/\")\n",
    "# activity_dir_controls = os.path.join(controls_dir, \"activity_data/\")\n",
    "\n",
    "os.chdir(adhd_dir)\n",
    "\n",
    "# Participant/patient info -- in particular, ADHD diagnosis status \n",
    "patient_info = pd.read_csv(\"patient_info.csv\", delimiter=\";\")\n",
    "patient_info['ID'] = patient_info['ID'].astype(\"string\").str.zfill(2)\n",
    "\n",
    "patient_info\n",
    "\n",
    "# os.chdir(hrv_dir)\n",
    "# hrv_data = pd.read_csv(\"patient_hr_1.csv\", delimiter=\";\")\n",
    "# hrv_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First, activity data feature extraction using sktime \n",
    "\n",
    "# Authors' function to read in activity file\n",
    "# Hicks et al. 2021\n",
    "# HYPERAKTIV: An Activity Dataset from Patients with Attention-Deficit/Hyperactivity Disorder (ADHD)\n",
    "def read_activity_file(filepath, patient_id):\n",
    "    data = [ ]\n",
    "    with open(filepath) as f:\n",
    "        csv_reader = csv.reader(f, delimiter=\";\")\n",
    "        next(csv_reader)\n",
    "        for line in csv_reader:\n",
    "            data.append([ datetime.strptime(line[0], \"%m-%d-%Y %H:%M\").timestamp(), int(line[1].split(\" \")[0])])\n",
    "    data = pd.DataFrame(data, columns=[\"TIME\", \"ACC\"])\n",
    "    data[\"ID\"] = patient_id\n",
    "    return data\n",
    "\n",
    "\n",
    "# Define function for preparing data\n",
    "def prepare_data(pt_directory, pt_info):\n",
    "\n",
    "    # Creating data frames for classification \n",
    "    all_participants = [] # List of dataframes (each dataframe is a different participant)\n",
    "    pt_ids = [] # List of participant IDs from raw data\n",
    "    for filepath in glob.glob(os.path.join(activity_dir, \"*.csv\")):\n",
    "        # print(\"Reading %s\" % filepath)\n",
    "        patient_id_raw = os.path.splitext(os.path.basename(filepath))[0]\n",
    "        patient_id = patient_id_raw.split(\"_\")[-1] # Find ID\n",
    "        \n",
    "        data = read_activity_file(filepath, patient_id)\n",
    "        pt_ids.append(patient_id) # These will be used to filter patient_info later\n",
    "\n",
    "        all_participants.append(data)\n",
    "\n",
    "    no_id_pts = []\n",
    "    for df in all_participants:\n",
    "        no_id_pts.append(df[[\"TIME\", \"ACC\"]]) # Remove \"categorical\" ID data\n",
    "\n",
    "    # Don't include participants in patient_info who weren't in the files\n",
    "    pt_info_clean = patient_info[patient_info.ID.isin(pt_ids)]\n",
    "\n",
    "    return no_id_pts, pt_info_clean\n",
    "\n",
    "# Define function for classification\n",
    "def classify(X, y, test_size, classifier, params):\n",
    "    # Split data\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size, random_state=42)\n",
    "\n",
    "    # Find biggest length of data for padding \n",
    "    lengths = []\n",
    "    for pt in X:\n",
    "        lengths.append(len(pt))\n",
    "\n",
    "    ### THIS WORKS DON'T MESS WITH THIS LINE ###\n",
    "    # padded_clf = PaddingTransformer(pad_length=max(lengths)) * RandomIntervalClassifier(n_intervals=5)\n",
    "    # padded_clf = PaddingTransformer(pad_length=max(lengths)) * RandomForestClassifier(n_estimators=100)\n",
    "    padded_clf = PaddingTransformer(pad_length=max(lengths)) * classifier(params)\n",
    "    padded_clf.fit(X_train, y_train)\n",
    "\n",
    "    # Model performance\n",
    "\n",
    "    y_pred = padded_clf.predict(X_test)\n",
    "\n",
    "    report = sklearn.metrics.classification_report(y_test, y_pred)\n",
    "\n",
    "    return report \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.81      0.76        21\n",
      "           1       0.64      0.50      0.56        14\n",
      "\n",
      "    accuracy                           0.69        35\n",
      "   macro avg       0.67      0.65      0.66        35\n",
      "weighted avg       0.68      0.69      0.68        35\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Classify with Random Forest as a test\n",
    "\n",
    "all_participants, pt_info = prepare_data(activity_dir, patient_info)\n",
    "\n",
    "metrics = classify(all_participants, pt_info[\"ADHD\"], 0.3, RandomForestClassifier, 1000)\n",
    "\n",
    "print(metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "InvalidParameterError",
     "evalue": "The 'penalty' parameter of LogisticRegression must be a str among {'l2', 'l1', 'elasticnet'} or None. Got {'penalty': 'l2', 'C': 1.0, 'class_weight': 'balanced', 'random_state': 0, 'solver': 'liblinear', 'n_jobs': 1} instead.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mInvalidParameterError\u001b[0m                     Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[13], line 28\u001b[0m\n\u001b[0;32m     18\u001b[0m _PARAMS_XGB \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m     19\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrandom_state\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;241m0\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mverbosity\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;241m0\u001b[39m,\n\u001b[0;32m     20\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mobjective\u001b[39m\u001b[38;5;124m'\u001b[39m:\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbinary:logistic\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m     21\u001b[0m }\n\u001b[0;32m     23\u001b[0m _PARAMS_LIGHTGB \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m     24\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrandom_state\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;241m0\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mverbosity\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;241m0\u001b[39m,\n\u001b[0;32m     25\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mobjective\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbinary\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     26\u001b[0m }\n\u001b[1;32m---> 28\u001b[0m metrics_logreg \u001b[38;5;241m=\u001b[39m \u001b[43mclassify\u001b[49m\u001b[43m(\u001b[49m\u001b[43mall_participants\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpt_info\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mADHD\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0.3\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mLogisticRegression\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_PARAMS_LORGREG\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     29\u001b[0m metrics_rfc \u001b[38;5;241m=\u001b[39m classify(all_participants, pt_info[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mADHD\u001b[39m\u001b[38;5;124m\"\u001b[39m], \u001b[38;5;241m0.3\u001b[39m, RandomForestClassifier, _PARAMS_RFC)\n\u001b[0;32m     30\u001b[0m metrics_xgb \u001b[38;5;241m=\u001b[39m classify(all_participants, patient_info[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mADHD\u001b[39m\u001b[38;5;124m\"\u001b[39m], \u001b[38;5;241m0.3\u001b[39m, XGBClassifier, _PARAMS_XGB)\n",
      "Cell \u001b[1;32mIn[11], line 57\u001b[0m, in \u001b[0;36mclassify\u001b[1;34m(X, y, test_size, classifier, params)\u001b[0m\n\u001b[0;32m     53\u001b[0m \u001b[38;5;66;03m### THIS WORKS DON'T MESS WITH THIS LINE ###\u001b[39;00m\n\u001b[0;32m     54\u001b[0m \u001b[38;5;66;03m# padded_clf = PaddingTransformer(pad_length=max(lengths)) * RandomIntervalClassifier(n_intervals=5)\u001b[39;00m\n\u001b[0;32m     55\u001b[0m \u001b[38;5;66;03m# padded_clf = PaddingTransformer(pad_length=max(lengths)) * RandomForestClassifier(n_estimators=100)\u001b[39;00m\n\u001b[0;32m     56\u001b[0m padded_clf \u001b[38;5;241m=\u001b[39m PaddingTransformer(pad_length\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mmax\u001b[39m(lengths)) \u001b[38;5;241m*\u001b[39m classifier(params)\n\u001b[1;32m---> 57\u001b[0m \u001b[43mpadded_clf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     59\u001b[0m \u001b[38;5;66;03m# Model performance\u001b[39;00m\n\u001b[0;32m     61\u001b[0m y_pred \u001b[38;5;241m=\u001b[39m padded_clf\u001b[38;5;241m.\u001b[39mpredict(X_test)\n",
      "File \u001b[1;32mc:\\Users\\maksi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sktime\\classification\\base.py:272\u001b[0m, in \u001b[0;36mBaseClassifier.fit\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m    267\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(\n\u001b[0;32m    268\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mself.n_jobs must be set if capability:multithreading is True\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    269\u001b[0m         )\n\u001b[0;32m    271\u001b[0m \u001b[38;5;66;03m# pass coerced and checked data to inner _fit\u001b[39;00m\n\u001b[1;32m--> 272\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    273\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfit_time_ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mint\u001b[39m(\u001b[38;5;28mround\u001b[39m(time\u001b[38;5;241m.\u001b[39mtime() \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m1000\u001b[39m)) \u001b[38;5;241m-\u001b[39m start\n\u001b[0;32m    275\u001b[0m \u001b[38;5;66;03m# this should happen last: fitted state is set to True\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\maksi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sktime\\classification\\compose\\_pipeline.py:562\u001b[0m, in \u001b[0;36mSklearnClassifierPipeline._fit\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m    560\u001b[0m Xt \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtransformers_\u001b[38;5;241m.\u001b[39mfit_transform(X\u001b[38;5;241m=\u001b[39mX, y\u001b[38;5;241m=\u001b[39my)\n\u001b[0;32m    561\u001b[0m Xt_sklearn \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_convert_X_to_sklearn(Xt)\n\u001b[1;32m--> 562\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclassifier_\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mXt_sklearn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    564\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\maksi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\base.py:1382\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1377\u001b[0m partial_fit_and_fitted \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m   1378\u001b[0m     fit_method\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpartial_fit\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m _is_fitted(estimator)\n\u001b[0;32m   1379\u001b[0m )\n\u001b[0;32m   1381\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m global_skip_validation \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m partial_fit_and_fitted:\n\u001b[1;32m-> 1382\u001b[0m     \u001b[43mestimator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_validate_params\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1384\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m   1385\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m   1386\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m   1387\u001b[0m     )\n\u001b[0;32m   1388\u001b[0m ):\n\u001b[0;32m   1389\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fit_method(estimator, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\maksi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\base.py:436\u001b[0m, in \u001b[0;36mBaseEstimator._validate_params\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    428\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_validate_params\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    429\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Validate types and values of constructor parameters\u001b[39;00m\n\u001b[0;32m    430\u001b[0m \n\u001b[0;32m    431\u001b[0m \u001b[38;5;124;03m    The expected type and values must be defined in the `_parameter_constraints`\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    434\u001b[0m \u001b[38;5;124;03m    accepted constraints.\u001b[39;00m\n\u001b[0;32m    435\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 436\u001b[0m     \u001b[43mvalidate_parameter_constraints\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    437\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_parameter_constraints\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    438\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_params\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdeep\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    439\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcaller_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;18;43m__class__\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;18;43m__name__\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    440\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\maksi\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py:98\u001b[0m, in \u001b[0;36mvalidate_parameter_constraints\u001b[1;34m(parameter_constraints, params, caller_name)\u001b[0m\n\u001b[0;32m     92\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     93\u001b[0m     constraints_str \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m     94\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mjoin([\u001b[38;5;28mstr\u001b[39m(c)\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mfor\u001b[39;00m\u001b[38;5;250m \u001b[39mc\u001b[38;5;250m \u001b[39m\u001b[38;5;129;01min\u001b[39;00m\u001b[38;5;250m \u001b[39mconstraints[:\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]])\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m or\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     95\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mconstraints[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     96\u001b[0m     )\n\u001b[1;32m---> 98\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m InvalidParameterError(\n\u001b[0;32m     99\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mparam_name\u001b[38;5;132;01m!r}\u001b[39;00m\u001b[38;5;124m parameter of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcaller_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must be\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    100\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mconstraints_str\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m. Got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mparam_val\u001b[38;5;132;01m!r}\u001b[39;00m\u001b[38;5;124m instead.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    101\u001b[0m )\n",
      "\u001b[1;31mInvalidParameterError\u001b[0m: The 'penalty' parameter of LogisticRegression must be a str among {'l2', 'l1', 'elasticnet'} or None. Got {'penalty': 'l2', 'C': 1.0, 'class_weight': 'balanced', 'random_state': 0, 'solver': 'liblinear', 'n_jobs': 1} instead."
     ]
    }
   ],
   "source": [
    "# Original author params for each model\n",
    "\n",
    "_PARAMS_LORGREG = {\n",
    "    \"penalty\": \"l2\", \"C\": 1.0, \"class_weight\": \"balanced\",\n",
    "    \"random_state\": 0, \"solver\": \"liblinear\", \"n_jobs\": 1\n",
    "}\n",
    "\n",
    "_PARAMS_RFC = {\n",
    "    \"n_estimators\": 1000,\n",
    "    \"max_depth\": None, # Max features given as auto, changed to default\n",
    "    \"min_samples_split\": 2, \"min_samples_leaf\": 1,\n",
    "    \"min_weight_fraction_leaf\": 0.0,\n",
    "    \"max_leaf_nodes\": None, \"bootstrap\": True,\n",
    "    \"oob_score\": False, \"n_jobs\": -1, \"random_state\": 0,\n",
    "    \"class_weight\": \"balanced\"\n",
    "}\n",
    "\n",
    "_PARAMS_XGB = {\n",
    "    \"random_state\": 0, \"verbosity\": 0,\n",
    "    'objective':'binary:logistic'\n",
    "}\n",
    "\n",
    "_PARAMS_LIGHTGB = {\n",
    "    \"random_state\": 0, \"verbosity\": 0,\n",
    "    \"objective\": \"binary\"\n",
    "}\n",
    "\n",
    "metrics_logreg = classify(all_participants, pt_info[\"ADHD\"], 0.3, LogisticRegression, _PARAMS_LORGREG)\n",
    "metrics_rfc = classify(all_participants, pt_info[\"ADHD\"], 0.3, RandomForestClassifier, _PARAMS_RFC)\n",
    "metrics_xgb = classify(all_participants, patient_info[\"ADHD\"], 0.3, XGBClassifier, _PARAMS_XGB)\n",
    "metrics_lgbm = classify(all_participants, patient_info[\"ADHD\"], 0.3, LGBMClassifier, _PARAMS_LIGHTGB)\n",
    "\n",
    "print(\"Logistic Regression\")\n",
    "print(metrics_logreg)\n",
    "\n",
    "print(\"Random Forest\")\n",
    "print(metrics_rfc)\n",
    "\n",
    "print(\"XGB\")\n",
    "print(metrics_xgb)\n",
    "\n",
    "print(\"LGBM\")\n",
    "print(metrics_lgbm)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
