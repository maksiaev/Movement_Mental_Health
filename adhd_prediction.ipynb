{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ADHD Classification Based on Activity\n",
    "# Purpose: Determine whether activity can predict diagnosis of ADHD\n",
    "# Author: Alexander Maksiaev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TIMESTAMP</th>\n",
       "      <th>ACTIVITY</th>\n",
       "      <th>ID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>02-23-2009 16:00</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>02-23-2009 16:01</td>\n",
       "      <td>195</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>02-23-2009 16:02</td>\n",
       "      <td>240</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>02-23-2009 16:03</td>\n",
       "      <td>209</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>02-23-2009 16:04</td>\n",
       "      <td>202</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8631</th>\n",
       "      <td>03-01-2009 15:51</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8632</th>\n",
       "      <td>03-01-2009 15:52</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8633</th>\n",
       "      <td>03-01-2009 15:53</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8634</th>\n",
       "      <td>03-01-2009 15:54</td>\n",
       "      <td>131</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8635</th>\n",
       "      <td>03-01-2009 15:55</td>\n",
       "      <td>54</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8636 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             TIMESTAMP  ACTIVITY  ID\n",
       "0     02-23-2009 16:00         0   1\n",
       "1     02-23-2009 16:01       195   1\n",
       "2     02-23-2009 16:02       240   1\n",
       "3     02-23-2009 16:03       209   1\n",
       "4     02-23-2009 16:04       202   1\n",
       "...                ...       ...  ..\n",
       "8631  03-01-2009 15:51         0   1\n",
       "8632  03-01-2009 15:52         0   1\n",
       "8633  03-01-2009 15:53         0   1\n",
       "8634  03-01-2009 15:54       131   1\n",
       "8635  03-01-2009 15:55        54   1\n",
       "\n",
       "[8636 rows x 3 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Housekeeping\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "from tsfresh import extract_features\n",
    "from tsfresh import extract_relevant_features\n",
    "from tsfresh import select_features\n",
    "import glob\n",
    "import os\n",
    "\n",
    "# Directories\n",
    "main_dir = \"c:/Users/maksi/Documents/Statistics/Projects/Movement_Mental_Health/\"\n",
    "\n",
    "adhd_dir = os.path.join(main_dir, \"hyperaktiv/\")\n",
    "activity_dir = os.path.join(adhd_dir, \"activity_data/\")\n",
    "hrv_dir = os.path.join(adhd_dir, \"hrv_data/\")\n",
    "controls_dir = os.path.join(adhd_dir, \"hyperaktiv_with_controls/hyperaktiv_with_controls/\")\n",
    "activity_dir_controls = os.path.join(controls_dir, \"activity_data/\")\n",
    "\n",
    "os.chdir(adhd_dir)\n",
    "\n",
    "# Main files\n",
    "patient_info = pd.read_csv(\"patient_info.csv\", delimiter=\";\")\n",
    "features = pd.read_csv(\"features.csv\", delimiter=\";\")\n",
    "patient_info\n",
    "# print(features)\n",
    "\n",
    "os.chdir(activity_dir)\n",
    "activity_data_01 = pd.read_csv(\"patient_activity_01.csv\", delimiter=\";\")\n",
    "activity_data_01[\"ID\"] = 1\n",
    "activity_data_01\n",
    "\n",
    "# os.chdir(hrv_dir)\n",
    "# hrv_data = pd.read_csv(\"patient_hr_1.csv\", delimiter=\";\")\n",
    "# hrv_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data initialization\n",
    "\n",
    "os.chdir(controls_dir)\n",
    "\n",
    "controls_info = pd.read_csv(\"patient_info.csv\", delimiter=\";\") # Includes patients as well\n",
    "# print(controls_info)\n",
    "\n",
    "adhd_patients = controls_info[controls_info[\"ADHD\"] == 1.0] # ADHD only\n",
    "# print(adhd_patients)\n",
    "# print(controls_info.columns)\n",
    "\n",
    "controls = controls_info[np.sum(controls_info.loc[:, \"ADHD\":\"OTHER\"], axis=1) == 0] # Neurotypicals only\n",
    "non_adhd_controls = controls_info[controls_info[\"ADHD\"] == 0] # Non-ADHD only\n",
    "# print(controls)\n",
    "# print(non_adhd_controls)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1494322\n",
      "82323\n"
     ]
    }
   ],
   "source": [
    "# Concat all activity dataframes\n",
    "\n",
    "os.chdir(activity_dir_controls)\n",
    "\n",
    "csv_files = glob.glob(\"*.csv\")\n",
    "\n",
    "# Create an empty dataframe to store the combined data\n",
    "mega_activity_df = pd.DataFrame()\n",
    "\n",
    "# Loop through each CSV file and append it to the combined dataframe\n",
    "for file in csv_files:\n",
    "    file_name_pieces = str.split(file, sep=\"_\")\n",
    "    pt_id = file_name_pieces[-1][:-4] # Last part of the file name is patient id, without the .csv\n",
    "    df = pd.read_csv(file, delimiter=\";\")\n",
    "    df[\"ID\"] = int(pt_id)\n",
    "    mega_activity_df = pd.concat([mega_activity_df, df], ignore_index=True)\n",
    "\n",
    "mega_activity_df\n",
    "print(len(mega_activity_df))\n",
    "mega_activity_df = mega_activity_df.dropna()\n",
    "\n",
    "print(len(mega_activity_df[mega_activity_df[\"ID\"] <= 5]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ID\n",
      "1     1.0\n",
      "2     1.0\n",
      "3     0.0\n",
      "5     0.0\n",
      "7     0.0\n",
      "8     0.0\n",
      "9     1.0\n",
      "10    0.0\n",
      "Name: ADHD, dtype: float64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Feature Extraction:   0%|          | 0/8 [00:38<?, ?it/s]\n"
     ]
    },
    {
     "ename": "MemoryError",
     "evalue": "Unable to allocate 1.67 GiB for an array with shape (8634, 8634, 3) and data type int64",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRemoteTraceback\u001b[0m                           Traceback (most recent call last)",
      "\u001b[1;31mRemoteTraceback\u001b[0m: \n\"\"\"\nTraceback (most recent call last):\n  File \"c:\\Users\\maksi\\anaconda3\\Lib\\multiprocessing\\pool.py\", line 125, in worker\n    result = (True, func(*args, **kwds))\n                    ^^^^^^^^^^^^^^^^^^^\n  File \"c:\\Users\\maksi\\anaconda3\\Lib\\site-packages\\tsfresh\\utilities\\distribution.py\", line 43, in _function_with_partly_reduce\n    results = list(itertools.chain.from_iterable(results))\n              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"c:\\Users\\maksi\\anaconda3\\Lib\\site-packages\\tsfresh\\utilities\\distribution.py\", line 42, in <genexpr>\n    results = (map_function(chunk, **kwargs) for chunk in chunk_list)\n               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"c:\\Users\\maksi\\anaconda3\\Lib\\site-packages\\tsfresh\\feature_extraction\\extraction.py\", line 386, in _do_extraction_on_chunk\n    return list(_f())\n           ^^^^^^^^^^\n  File \"c:\\Users\\maksi\\anaconda3\\Lib\\site-packages\\tsfresh\\feature_extraction\\extraction.py\", line 374, in _f\n    for key, item in result:\n  File \"c:\\Users\\maksi\\anaconda3\\Lib\\site-packages\\tsfresh\\feature_extraction\\extraction.py\", line 368, in <genexpr>\n    (convert_to_output_format(param), func(x, **param))\n                                      ^^^^^^^^^^^^^^^^\n  File \"c:\\Users\\maksi\\anaconda3\\Lib\\site-packages\\tsfresh\\feature_extraction\\feature_calculators.py\", line 1790, in approximate_entropy\n    return np.abs(_phi(m) - _phi(m + 1))\n                            ^^^^^^^^^^^\n  File \"c:\\Users\\maksi\\anaconda3\\Lib\\site-packages\\tsfresh\\feature_extraction\\feature_calculators.py\", line 1785, in _phi\n    np.max(np.abs(x_re[:, np.newaxis] - x_re[np.newaxis, :]), axis=2) <= r,\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nnumpy.core._exceptions._ArrayMemoryError: Unable to allocate 1.67 GiB for an array with shape (8634, 8634, 3) and data type int64\n\"\"\"",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[25], line 24\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[38;5;28mprint\u001b[39m(y\u001b[38;5;241m.\u001b[39mloc[\u001b[38;5;241m1\u001b[39m:\u001b[38;5;241m10\u001b[39m])\n\u001b[0;32m     20\u001b[0m \u001b[38;5;66;03m# activity_data_01.plot(figsize=(10,10))\u001b[39;00m\n\u001b[0;32m     21\u001b[0m \u001b[38;5;66;03m# plt.show()\u001b[39;00m\n\u001b[0;32m     22\u001b[0m \n\u001b[0;32m     23\u001b[0m \u001b[38;5;66;03m# Find relevant features using tsfresh\u001b[39;00m\n\u001b[1;32m---> 24\u001b[0m relevant_features \u001b[38;5;241m=\u001b[39m extract_relevant_features(mega_activity_df[mega_activity_df[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mID\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m10\u001b[39m], y\u001b[38;5;241m.\u001b[39mloc[\u001b[38;5;241m1\u001b[39m:\u001b[38;5;241m10\u001b[39m], column_id\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mID\u001b[39m\u001b[38;5;124m'\u001b[39m, column_sort\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTIMESTAMP\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     26\u001b[0m relevant_features\u001b[38;5;241m.\u001b[39mhead()\n",
      "File \u001b[1;32mc:\\Users\\maksi\\anaconda3\\Lib\\site-packages\\tsfresh\\convenience\\relevant_extraction.py:182\u001b[0m, in \u001b[0;36mextract_relevant_features\u001b[1;34m(timeseries_container, y, X, default_fc_parameters, kind_to_fc_parameters, column_id, column_sort, column_kind, column_value, show_warnings, disable_progressbar, profile, profiling_filename, profiling_sorting, test_for_binary_target_binary_feature, test_for_binary_target_real_feature, test_for_real_target_binary_feature, test_for_real_target_real_feature, fdr_level, hypotheses_independent, n_jobs, distributor, chunksize, ml_task)\u001b[0m\n\u001b[0;32m    176\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(ids_y \u001b[38;5;241m-\u001b[39m ids_container) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m    177\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    178\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe following ids are in y but are missing inside the time series container: \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    179\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(ids_y \u001b[38;5;241m-\u001b[39m ids_container)\n\u001b[0;32m    180\u001b[0m         )\n\u001b[1;32m--> 182\u001b[0m X_ext \u001b[38;5;241m=\u001b[39m extract_features(\n\u001b[0;32m    183\u001b[0m     timeseries_container,\n\u001b[0;32m    184\u001b[0m     default_fc_parameters\u001b[38;5;241m=\u001b[39mdefault_fc_parameters,\n\u001b[0;32m    185\u001b[0m     kind_to_fc_parameters\u001b[38;5;241m=\u001b[39mkind_to_fc_parameters,\n\u001b[0;32m    186\u001b[0m     show_warnings\u001b[38;5;241m=\u001b[39mshow_warnings,\n\u001b[0;32m    187\u001b[0m     disable_progressbar\u001b[38;5;241m=\u001b[39mdisable_progressbar,\n\u001b[0;32m    188\u001b[0m     profile\u001b[38;5;241m=\u001b[39mprofile,\n\u001b[0;32m    189\u001b[0m     profiling_filename\u001b[38;5;241m=\u001b[39mprofiling_filename,\n\u001b[0;32m    190\u001b[0m     profiling_sorting\u001b[38;5;241m=\u001b[39mprofiling_sorting,\n\u001b[0;32m    191\u001b[0m     n_jobs\u001b[38;5;241m=\u001b[39mn_jobs,\n\u001b[0;32m    192\u001b[0m     chunksize\u001b[38;5;241m=\u001b[39mchunksize,\n\u001b[0;32m    193\u001b[0m     column_id\u001b[38;5;241m=\u001b[39mcolumn_id,\n\u001b[0;32m    194\u001b[0m     column_sort\u001b[38;5;241m=\u001b[39mcolumn_sort,\n\u001b[0;32m    195\u001b[0m     column_kind\u001b[38;5;241m=\u001b[39mcolumn_kind,\n\u001b[0;32m    196\u001b[0m     column_value\u001b[38;5;241m=\u001b[39mcolumn_value,\n\u001b[0;32m    197\u001b[0m     distributor\u001b[38;5;241m=\u001b[39mdistributor,\n\u001b[0;32m    198\u001b[0m     impute_function\u001b[38;5;241m=\u001b[39mimpute,\n\u001b[0;32m    199\u001b[0m )\n\u001b[0;32m    201\u001b[0m X_sel \u001b[38;5;241m=\u001b[39m select_features(\n\u001b[0;32m    202\u001b[0m     X_ext,\n\u001b[0;32m    203\u001b[0m     y,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    213\u001b[0m     ml_task\u001b[38;5;241m=\u001b[39mml_task,\n\u001b[0;32m    214\u001b[0m )\n\u001b[0;32m    216\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m X \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\maksi\\anaconda3\\Lib\\site-packages\\tsfresh\\feature_extraction\\extraction.py:164\u001b[0m, in \u001b[0;36mextract_features\u001b[1;34m(timeseries_container, default_fc_parameters, kind_to_fc_parameters, column_id, column_sort, column_kind, column_value, chunksize, n_jobs, show_warnings, disable_progressbar, impute_function, profile, profiling_filename, profiling_sorting, distributor, pivot)\u001b[0m\n\u001b[0;32m    161\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    162\u001b[0m     warnings\u001b[38;5;241m.\u001b[39msimplefilter(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdefault\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m--> 164\u001b[0m result \u001b[38;5;241m=\u001b[39m _do_extraction(\n\u001b[0;32m    165\u001b[0m     df\u001b[38;5;241m=\u001b[39mtimeseries_container,\n\u001b[0;32m    166\u001b[0m     column_id\u001b[38;5;241m=\u001b[39mcolumn_id,\n\u001b[0;32m    167\u001b[0m     column_value\u001b[38;5;241m=\u001b[39mcolumn_value,\n\u001b[0;32m    168\u001b[0m     column_kind\u001b[38;5;241m=\u001b[39mcolumn_kind,\n\u001b[0;32m    169\u001b[0m     column_sort\u001b[38;5;241m=\u001b[39mcolumn_sort,\n\u001b[0;32m    170\u001b[0m     n_jobs\u001b[38;5;241m=\u001b[39mn_jobs,\n\u001b[0;32m    171\u001b[0m     chunk_size\u001b[38;5;241m=\u001b[39mchunksize,\n\u001b[0;32m    172\u001b[0m     disable_progressbar\u001b[38;5;241m=\u001b[39mdisable_progressbar,\n\u001b[0;32m    173\u001b[0m     show_warnings\u001b[38;5;241m=\u001b[39mshow_warnings,\n\u001b[0;32m    174\u001b[0m     default_fc_parameters\u001b[38;5;241m=\u001b[39mdefault_fc_parameters,\n\u001b[0;32m    175\u001b[0m     kind_to_fc_parameters\u001b[38;5;241m=\u001b[39mkind_to_fc_parameters,\n\u001b[0;32m    176\u001b[0m     distributor\u001b[38;5;241m=\u001b[39mdistributor,\n\u001b[0;32m    177\u001b[0m     pivot\u001b[38;5;241m=\u001b[39mpivot,\n\u001b[0;32m    178\u001b[0m )\n\u001b[0;32m    180\u001b[0m \u001b[38;5;66;03m# Impute the result if requested\u001b[39;00m\n\u001b[0;32m    181\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m impute_function \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\maksi\\anaconda3\\Lib\\site-packages\\tsfresh\\feature_extraction\\extraction.py:294\u001b[0m, in \u001b[0;36m_do_extraction\u001b[1;34m(df, column_id, column_value, column_kind, column_sort, default_fc_parameters, kind_to_fc_parameters, n_jobs, chunk_size, disable_progressbar, show_warnings, distributor, pivot)\u001b[0m\n\u001b[0;32m    286\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mthe passed distributor is not an DistributorBaseClass object\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    288\u001b[0m kwargs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mdict\u001b[39m(\n\u001b[0;32m    289\u001b[0m     default_fc_parameters\u001b[38;5;241m=\u001b[39mdefault_fc_parameters,\n\u001b[0;32m    290\u001b[0m     kind_to_fc_parameters\u001b[38;5;241m=\u001b[39mkind_to_fc_parameters,\n\u001b[0;32m    291\u001b[0m     show_warnings\u001b[38;5;241m=\u001b[39mshow_warnings,\n\u001b[0;32m    292\u001b[0m )\n\u001b[1;32m--> 294\u001b[0m result \u001b[38;5;241m=\u001b[39m distributor\u001b[38;5;241m.\u001b[39mmap_reduce(\n\u001b[0;32m    295\u001b[0m     _do_extraction_on_chunk,\n\u001b[0;32m    296\u001b[0m     data\u001b[38;5;241m=\u001b[39mdata,\n\u001b[0;32m    297\u001b[0m     chunk_size\u001b[38;5;241m=\u001b[39mchunk_size,\n\u001b[0;32m    298\u001b[0m     function_kwargs\u001b[38;5;241m=\u001b[39mkwargs,\n\u001b[0;32m    299\u001b[0m )\n\u001b[0;32m    301\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m pivot:\n\u001b[0;32m    302\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[1;32mc:\\Users\\maksi\\anaconda3\\Lib\\site-packages\\tsfresh\\utilities\\distribution.py:241\u001b[0m, in \u001b[0;36mIterableDistributorBaseClass.map_reduce\u001b[1;34m(self, map_function, data, function_kwargs, chunk_size, data_length)\u001b[0m\n\u001b[0;32m    234\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    235\u001b[0m     result \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    236\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdistribute(\n\u001b[0;32m    237\u001b[0m             _function_with_partly_reduce, chunk_generator, map_kwargs\n\u001b[0;32m    238\u001b[0m         ),\n\u001b[0;32m    239\u001b[0m     )\n\u001b[1;32m--> 241\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(itertools\u001b[38;5;241m.\u001b[39mchain\u001b[38;5;241m.\u001b[39mfrom_iterable(result))\n\u001b[0;32m    243\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclose()\n\u001b[0;32m    245\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[1;32mc:\\Users\\maksi\\anaconda3\\Lib\\site-packages\\tqdm\\std.py:1181\u001b[0m, in \u001b[0;36mtqdm.__iter__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1178\u001b[0m time \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_time\n\u001b[0;32m   1180\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 1181\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m obj \u001b[38;5;129;01min\u001b[39;00m iterable:\n\u001b[0;32m   1182\u001b[0m         \u001b[38;5;28;01myield\u001b[39;00m obj\n\u001b[0;32m   1183\u001b[0m         \u001b[38;5;66;03m# Update and possibly print the progressbar.\u001b[39;00m\n\u001b[0;32m   1184\u001b[0m         \u001b[38;5;66;03m# Note: does not call self.update(1) for speed optimisation.\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\maksi\\anaconda3\\Lib\\multiprocessing\\pool.py:873\u001b[0m, in \u001b[0;36mIMapIterator.next\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    871\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m success:\n\u001b[0;32m    872\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m value\n\u001b[1;32m--> 873\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m value\n",
      "File \u001b[1;32mc:\\Users\\maksi\\anaconda3\\Lib\\multiprocessing\\pool.py:125\u001b[0m, in \u001b[0;36mworker\u001b[1;34m()\u001b[0m\n\u001b[0;32m    123\u001b[0m job, i, func, args, kwds \u001b[38;5;241m=\u001b[39m task\n\u001b[0;32m    124\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 125\u001b[0m     result \u001b[38;5;241m=\u001b[39m (\u001b[38;5;28;01mTrue\u001b[39;00m, func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds))\n\u001b[0;32m    126\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    127\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m wrap_exception \u001b[38;5;129;01mand\u001b[39;00m func \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m _helper_reraises_exception:\n",
      "File \u001b[1;32mc:\\Users\\maksi\\anaconda3\\Lib\\site-packages\\tsfresh\\utilities\\distribution.py:43\u001b[0m, in \u001b[0;36m_function_with_partly_reduce\u001b[1;34m()\u001b[0m\n\u001b[0;32m     41\u001b[0m kwargs \u001b[38;5;241m=\u001b[39m kwargs \u001b[38;5;129;01mor\u001b[39;00m {}\n\u001b[0;32m     42\u001b[0m results \u001b[38;5;241m=\u001b[39m (map_function(chunk, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs) \u001b[38;5;28;01mfor\u001b[39;00m chunk \u001b[38;5;129;01min\u001b[39;00m chunk_list)\n\u001b[1;32m---> 43\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(itertools\u001b[38;5;241m.\u001b[39mchain\u001b[38;5;241m.\u001b[39mfrom_iterable(results))\n\u001b[0;32m     44\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m results\n",
      "File \u001b[1;32mc:\\Users\\maksi\\anaconda3\\Lib\\site-packages\\tsfresh\\utilities\\distribution.py:42\u001b[0m, in \u001b[0;36m<genexpr>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     25\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m     26\u001b[0m \u001b[38;5;124;03mSmall helper function to call a function (map_function)\u001b[39;00m\n\u001b[0;32m     27\u001b[0m \u001b[38;5;124;03mon a list of data chunks (chunk_list) and convert the results into\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     39\u001b[0m \u001b[38;5;124;03m:rtype: list\u001b[39;00m\n\u001b[0;32m     40\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m     41\u001b[0m kwargs \u001b[38;5;241m=\u001b[39m kwargs \u001b[38;5;129;01mor\u001b[39;00m {}\n\u001b[1;32m---> 42\u001b[0m results \u001b[38;5;241m=\u001b[39m (map_function(chunk, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs) \u001b[38;5;28;01mfor\u001b[39;00m chunk \u001b[38;5;129;01min\u001b[39;00m chunk_list)\n\u001b[0;32m     43\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(itertools\u001b[38;5;241m.\u001b[39mchain\u001b[38;5;241m.\u001b[39mfrom_iterable(results))\n\u001b[0;32m     44\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m results\n",
      "File \u001b[1;32mc:\\Users\\maksi\\anaconda3\\Lib\\site-packages\\tsfresh\\feature_extraction\\extraction.py:386\u001b[0m, in \u001b[0;36m_do_extraction_on_chunk\u001b[1;34m()\u001b[0m\n\u001b[0;32m    383\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    384\u001b[0m     warnings\u001b[38;5;241m.\u001b[39msimplefilter(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdefault\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m--> 386\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mlist\u001b[39m(_f())\n",
      "File \u001b[1;32mc:\\Users\\maksi\\anaconda3\\Lib\\site-packages\\tsfresh\\feature_extraction\\extraction.py:374\u001b[0m, in \u001b[0;36m_f\u001b[1;34m()\u001b[0m\n\u001b[0;32m    371\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    372\u001b[0m         result \u001b[38;5;241m=\u001b[39m [(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m, func(x))]\n\u001b[1;32m--> 374\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m key, item \u001b[38;5;129;01min\u001b[39;00m result:\n\u001b[0;32m    375\u001b[0m     feature_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mstr\u001b[39m(kind) \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m func\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\n\u001b[0;32m    376\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m key:\n",
      "File \u001b[1;32mc:\\Users\\maksi\\anaconda3\\Lib\\site-packages\\tsfresh\\feature_extraction\\extraction.py:368\u001b[0m, in \u001b[0;36m<genexpr>\u001b[1;34m()\u001b[0m\n\u001b[0;32m    365\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    366\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m parameter_list:\n\u001b[0;32m    367\u001b[0m         result \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m--> 368\u001b[0m             (convert_to_output_format(param), func(x, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mparam))\n\u001b[0;32m    369\u001b[0m             \u001b[38;5;28;01mfor\u001b[39;00m param \u001b[38;5;129;01min\u001b[39;00m parameter_list\n\u001b[0;32m    370\u001b[0m         )\n\u001b[0;32m    371\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    372\u001b[0m         result \u001b[38;5;241m=\u001b[39m [(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m, func(x))]\n",
      "File \u001b[1;32mc:\\Users\\maksi\\anaconda3\\Lib\\site-packages\\tsfresh\\feature_extraction\\feature_calculators.py:1790\u001b[0m, in \u001b[0;36mapproximate_entropy\u001b[1;34m()\u001b[0m\n\u001b[0;32m   1784\u001b[0m     C \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39msum(\n\u001b[0;32m   1785\u001b[0m         np\u001b[38;5;241m.\u001b[39mmax(np\u001b[38;5;241m.\u001b[39mabs(x_re[:, np\u001b[38;5;241m.\u001b[39mnewaxis] \u001b[38;5;241m-\u001b[39m x_re[np\u001b[38;5;241m.\u001b[39mnewaxis, :]), axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m) \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m r,\n\u001b[0;32m   1786\u001b[0m         axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m,\n\u001b[0;32m   1787\u001b[0m     ) \u001b[38;5;241m/\u001b[39m (N \u001b[38;5;241m-\u001b[39m m \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m   1788\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m np\u001b[38;5;241m.\u001b[39msum(np\u001b[38;5;241m.\u001b[39mlog(C)) \u001b[38;5;241m/\u001b[39m (N \u001b[38;5;241m-\u001b[39m m \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1.0\u001b[39m)\n\u001b[1;32m-> 1790\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m np\u001b[38;5;241m.\u001b[39mabs(_phi(m) \u001b[38;5;241m-\u001b[39m _phi(m \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m))\n",
      "File \u001b[1;32mc:\\Users\\maksi\\anaconda3\\Lib\\site-packages\\tsfresh\\feature_extraction\\feature_calculators.py:1785\u001b[0m, in \u001b[0;36m_phi\u001b[1;34m()\u001b[0m\n\u001b[0;32m   1782\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_phi\u001b[39m(m):\n\u001b[0;32m   1783\u001b[0m     x_re \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray([x[i : i \u001b[38;5;241m+\u001b[39m m] \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(N \u001b[38;5;241m-\u001b[39m m \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m)])\n\u001b[0;32m   1784\u001b[0m     C \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39msum(\n\u001b[1;32m-> 1785\u001b[0m         np\u001b[38;5;241m.\u001b[39mmax(np\u001b[38;5;241m.\u001b[39mabs(x_re[:, np\u001b[38;5;241m.\u001b[39mnewaxis] \u001b[38;5;241m-\u001b[39m x_re[np\u001b[38;5;241m.\u001b[39mnewaxis, :]), axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m) \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m r,\n\u001b[0;32m   1786\u001b[0m         axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m,\n\u001b[0;32m   1787\u001b[0m     ) \u001b[38;5;241m/\u001b[39m (N \u001b[38;5;241m-\u001b[39m m \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m   1788\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m np\u001b[38;5;241m.\u001b[39msum(np\u001b[38;5;241m.\u001b[39mlog(C)) \u001b[38;5;241m/\u001b[39m (N \u001b[38;5;241m-\u001b[39m m \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1.0\u001b[39m)\n",
      "\u001b[1;31mMemoryError\u001b[0m: Unable to allocate 1.67 GiB for an array with shape (8634, 8634, 3) and data type int64"
     ]
    }
   ],
   "source": [
    "# Pre-processing: Activity\n",
    "\n",
    "# Pts with motor activity recordings\n",
    "active_controls = controls_info[controls_info[\"ACC\"] == 1]\n",
    "# print(active_controls)\n",
    "\n",
    "# Each pt has their own csv file...\n",
    "# demographics_01 = active_controls[active_controls[\"ID\"] == 1]\n",
    "y = pd.Series(active_controls[\"ADHD\"], index=active_controls[\"ID\"])\n",
    "y = y.fillna(0)\n",
    "# y[\"ADHD\"] = active_controls[\"ADHD\"]\n",
    "# y.index = active_controls[\"ID\"]\n",
    "# y[\"ID\"] = y.index\n",
    "# print(y)\n",
    "# print(list(y.index))\n",
    "# print(demographics_01)\n",
    "# print(activity_data_01)\n",
    "print(y.loc[1:10])\n",
    "\n",
    "# activity_data_01.plot(figsize=(10,10))\n",
    "# plt.show()\n",
    "\n",
    "# Find relevant features using tsfresh\n",
    "relevant_features = extract_relevant_features(mega_activity_df[mega_activity_df[\"ID\"] <= 5], y.loc[1:5], column_id='ID', column_sort='TIMESTAMP')\n",
    "\n",
    "relevant_features.head()\n",
    "\n",
    "# X_full_train, X_full_test, y_train, y_test = train_test_split(relevant_features, y, test_size=.3, random_state=42)\n",
    "# X_filtered_train = select_features(X_full_train, y_train)\n",
    "# X_filtered_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting into training set and testing set\n",
    "\n",
    "# Don't let the machine know which ones are ADHD and which ones aren't\n",
    "X = controls_info.drop(\"ADHD\", axis=1)\n",
    "y = controls_info[\"ADHD\"]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30, stratify = y, random_state=2025)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
